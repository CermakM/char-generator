#!/bin/env python3
"""Scrape fonts from the given website

NOTES
-----
- you should check a websiteâ€™s Terms and Conditions before you scrape it
- be careful to read the statements about legal use of data
- usually, the data you scrape should not be used for commercial purposes
"""

import os
import sys

import re
import requests

from bs4 import BeautifulSoup


BASE_URL = 'https://www.ceskefonty.cz/'
FONT_DIR = os.path.abspath('fonts')


response = requests.get(BASE_URL)
soup = BeautifulSoup(response.content, 'html.parser')

page_label = soup.find('div', attrs={'id': 'pages-top'})
pages = page_label.find_all('li')[-1].text

try:
    # Get number of pages
    pages = int(pages)
except ValueError:
    print("Wrong page index:", pages or '-', file=sys.stderr)
    exit(1)

# Create font directory
# TODO: fix TOCTOU - implement file lock
if not os.path.isdir(FONT_DIR):
    os.mkdir(FONT_DIR)
else:
    if input("fonts folder already exists! Continue? [y/N]: ").lower() != 'y':
        print("Exiting", file=sys.stderr)
        exit(1)

_response_fail = 1
for page in range(1, pages + 1):
    url = BASE_URL + "?pg={page}".format(page=page)

    # check for consecutive response fails
    _response_fail = max(0, _response_fail - 1)

    response = requests.get(url)
    if not response.content:
        print("Failed to get response from:", url, file=sys.stderr)
        _response_fail += 1
        if _response_fail >= 3:
            exit(1)
        continue

    soup = BeautifulSoup(response.content, 'html.parser')

    # Get detail urls - lambda prevents duplicate urls
    details = soup.find_all(
            lambda t: len(dict.get(t.attrs, 'class', [])) == 1,
            attrs={'class': lambda c: c == 'detail'}
            )

    for detail in details:
        detail_url = detail.find('a').get('href')
        detail_content = requests.get(detail_url).content

        # get download url
        detail_sup = BeautifulSoup(detail_content, 'html.parser')
        download_url = detail_sup.find(
                'p', attrs={'class': 'detail'}
                ).find('a').get('href')

        search = re.search(r"([^/]+)\.(\w+)$", download_url)
        font_name = search.group(1)
        suffix = search.group(2)
        file_name = "{}.{}".format(font_name, suffix)

        font_dir = os.path.join(FONT_DIR, font_name)
        try:
            os.mkdir(font_dir)
        except FileExistsError:
            print("Skipped, font_name")
            continue

        print("Downloading", font_name, "...")
        content = requests.get(download_url).content

        if content and type(content) is bytes:
            with open(os.path.join(font_dir, file_name), 'wb') as font_file:
                font_file.write(content)

            print("Written", font_dir)

